{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import cv2 as cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this snippet iam selecting the 4 points in destination image (img_2) and source image(img_1)\n",
    "\n",
    "img_2 = mpimg.imread(\"C:/Users/shalh/Downloads/HW1/HW1_Image2.jpg\")\n",
    "img_1 = mpimg.imread(\"C:/Users/shalh/Downloads/HW1/HW1_image1.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(img_1)\n",
    "plt.title(\"Click 4 points, then press Enter\")\n",
    "plt.axis(\"on\")\n",
    "points_1 = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(img_2)\n",
    "plt.title(\"choose four from here\")\n",
    "plt.axis(\"on\")\n",
    "points_2 = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the DLT algorithm solving the nullspace of vector A yeilds h matrix(9x1) which can be reshaped into H matrix(3x3)\n",
    "print(\"Selected points_1:\", points_1)\n",
    "print(\"Selected points_2:\", points_2)\n",
    "def DLT(points_1,points_2):\n",
    "    A = []\n",
    "    for (u,v),(x,y) in zip(points_1,points_2):\n",
    "     A.append([-x, -y, -1, 0, 0, 0, u*x, u*y, u])\n",
    "     A.append([0, 0, 0, -x, -y, -1, v*x, v*y, v])\n",
    "\n",
    "    U,D,V_T = np.linalg.svd(A)\n",
    "\n",
    "\n",
    "    h = V_T[-1]\n",
    "    H = h.reshape(3,3)\n",
    "    return H\n",
    "\n",
    "H = DLT(points_1,points_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a869991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source image is warped using H and the dimension(width,height) of the destination image\n",
    "\n",
    "h_dst, w_dst = img_1.shape[:2]\n",
    "warped = cv2.warpPerspective(img_2, H, (w_dst, h_dst)) \n",
    "mask = warped > 0   \n",
    "\n",
    "result = img_1.copy()\n",
    "result[mask] = warped[mask]\n",
    "plt.imshow(result)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6bbcf0",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489cba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##in this snippet iam selecting the 8 points in destination image (img_1) and source image(img_2)\n",
    "\n",
    "\n",
    "img_1 = mpimg.imread(\"C:/Users/shalh/Downloads/HW1/HW1_image1.jpg\")\n",
    "img_2 = mpimg.imread(\"C:/Users/shalh/Downloads/HW1/HW1_image2.jpg\")\n",
    "\n",
    "plt.imshow(img_1)\n",
    "plt.title(\"Click 8 points8\")\n",
    "plt.axis(\"on\")\n",
    "points_1_n = plt.ginput(8)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(img_2)\n",
    "plt.title(\"choose 8 from here\")\n",
    "plt.axis(\"on\")\n",
    "points_2_n = plt.ginput(8)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating th H_n for 8 point selection \n",
    "H_n = DLT(points_1_n,points_2_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#warping the image 2 usinh H_n wrt image 1 using the mask to remove the black regions in the warped image \n",
    "hn_dst, wn_dst = img_1.shape[:2]\n",
    "warped_n = cv2.warpPerspective(img_2, H_n, (wn_dst, hn_dst)) \n",
    "plt.close()\n",
    "mask_n = warped_n > 0   \n",
    "\n",
    "result_n = img_1.copy()\n",
    "result_n[mask_n] = warped_n[mask_n]\n",
    "plt.imshow(result_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc74e73",
   "metadata": {},
   "source": [
    "- Average err for H matrix for 4 corner points is 9.325529997607403e-09\n",
    "- Average err for H matrix for 8 corner points is 8.404959314836097\n",
    "- Hence in the 4-point method achieved an average reprojection error of 52.22 pixels, while the 8-point method achieved 15.85 pixels. The 4-point method provides an exact solution that perfectly fits the 4 selected correspondences, but performs poorly on unseen data (like the extra 4 points we selected in 8 points selection method) with errors reaching over 300 pixels. The 8-point method uses least-squares fitting to minimize error across all points, resulting in more consistent performance and better generalization to new correspondences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Comparision H for 8\n",
    "transformed_2_n = []\n",
    "for (x,y) in points_2_n:\n",
    "    homo_n = np.array([x,y,1])\n",
    "    transformed = H_n@homo_n\n",
    "    transformed_2_n.append((transformed[0]/transformed[2],transformed[1]/transformed[2]))\n",
    "\n",
    "p1_n = np.array(points_1_n)\n",
    "p2t_n = np.array(transformed_2_n)\n",
    "\n",
    "difference_8 = np.linalg.norm(p2t_n-p1_n, axis=1)\n",
    "average_err_8 = np.mean(difference_8)\n",
    "print(\"average err for 8\", average_err_8)\n",
    "print(difference_8)\n",
    "\n",
    "#Comparision H for 4 \n",
    "transformed_2 = []\n",
    "for (x,y) in points_2:\n",
    "    homo = np.array([x,y,1])\n",
    "    transformed = H@homo\n",
    "    transformed_2.append((transformed[0]/transformed[2],transformed[1]/transformed[2]))\n",
    "\n",
    "p2_n = np.array([points_2_n[1],points_2_n[4],points_2_n[6],points_2_n[7]])\n",
    "p1 = np.array([points_1[0],points_1[1],points_1[2],points_1[3],points_1_n[1],points_1_n[5],points_1_n[6],points_1_n[7]])\n",
    "\n",
    "\n",
    "for (x,y) in p2_n:\n",
    "    homo = np.array([x,y,1])\n",
    "    transformed = H@homo\n",
    "    transformed_2.append((transformed[0]/transformed[2],transformed[1]/transformed[2]))\n",
    "\n",
    "p2t = np.array(transformed_2)\n",
    "p1 = np.array(p1)\n",
    "difference_4 = np.linalg.norm(p2t-p1, axis=1)\n",
    "average_err_4 = np.mean(difference_4)\n",
    "print(\"average err for 4\", average_err_4)\n",
    "print(difference_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61be38e9",
   "metadata": {},
   "source": [
    "Q_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 4 points from each image taking image3 as center image choosing pts btween image3to4 then image3to2 then image4to5 then image2to1\n",
    "image1 = mpimg.imread('C:/Users/shalh/Downloads/HW1/img_1.jpeg')\n",
    "image2 = mpimg.imread('C:/Users/shalh/Downloads/HW1/img_2.jpeg')\n",
    "image3 = mpimg.imread('C:/Users/shalh/Downloads/HW1/img_3.jpeg')\n",
    "image4 = mpimg.imread('C:/Users/shalh/Downloads/HW1/img_4.jpeg')\n",
    "image5 = mpimg.imread('C:/Users/shalh/Downloads/HW1/img_5.jpeg')\n",
    "\n",
    "\n",
    "plt.imshow(image3)\n",
    "plt.title(\"choose 4 points\")\n",
    "pts_im3 = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image4)\n",
    "plt.title(\"choose 4 points\")\n",
    "pts_im4 = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image3)\n",
    "plt.title(\"choose 4 points\")\n",
    "pts_im3_2 = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image2)\n",
    "plt.title(\"choose 4 points\")\n",
    "pts_im2 = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image4)\n",
    "plt.title(\"choose 4 points\")\n",
    "pts_im4_5 = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image5)\n",
    "plt.title(\"choose 4 points\")\n",
    "pts_im5 = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image2)\n",
    "plt.title(\"choose 4 points\")\n",
    "pts_im2_1 = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image1)\n",
    "plt.title(\"choose 4 points\")\n",
    "pts_im1 = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf935c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the H matrices for respetive projection like H_1 for image4to3\n",
    "H_1 = DLT(pts_im3,pts_im4)\n",
    "H_2 = DLT(pts_im3_2,pts_im2)\n",
    "H_3 = DLT(pts_im4_5,pts_im5)\n",
    "H_4 = DLT(pts_im2_1,pts_im1)\n",
    "print(\"H_1 determinant:\", np.linalg.det(H_1))\n",
    "print(\"H_2 determinant:\", np.linalg.det(H_2))\n",
    "w_dist_1, h_dist_1 = image3.shape[:2]\n",
    "\n",
    "warped_1 = cv2.warpPerspective(image4, H_1, (h_dist_1, w_dist_1))\n",
    "plt.imshow(warped_1)\n",
    "warped_2 = cv2.warpPerspective(image2,H_2,(h_dist_1, w_dist_1))\n",
    "plt.imshow(warped_2)\n",
    "warped_3 = cv2.warpPerspective(image5, H_3, (h_dist_1, w_dist_1))\n",
    "plt.imshow(warped_1)\n",
    "warped_4 = cv2.warpPerspective(image1,H_4,(h_dist_1, w_dist_1))\n",
    "plt.imshow(warped_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da76351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the corners of all images to get the idea od the canvas size \n",
    "\n",
    "plt.imshow(image4)\n",
    "plt.title(\"choose 4 corner points\")\n",
    "pts_im4corners = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image3)\n",
    "plt.title(\"choose 4 corner points\")\n",
    "pts_im3corners = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image2)\n",
    "plt.title(\"choose 4 corner points\")\n",
    "pts_im2corners = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image1)\n",
    "plt.title(\"choose 4 corner points\")\n",
    "pts_im1corners = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image5)\n",
    "plt.title(\"choose 4 corner points\")\n",
    "pts_im5corners = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(image2)\n",
    "plt.title(\"choose 4 corner points\")\n",
    "pts_im2corners = plt.ginput(4)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a function that gives the canvas width canvas height and the translation in x,y direction  by using all the transformed points wrt to image 3 to get the minimum and maximum bounds in both x,y direction \n",
    "#hence creating the canvas empty space \n",
    "def canvas_creator(image3_c,image2_c,image4_c,image1_c,image5_c):\n",
    "    points_new = []\n",
    "    for points in image4_c:\n",
    "       x,y = points\n",
    "       points_H = np.array([x,y,1])\n",
    "       x_n,y_n,z_n = H_1@points_H\n",
    "       x_n,y_n = x_n/z_n, y_n/z_n\n",
    "       points_new.append((x_n,y_n))\n",
    "\n",
    "    for points in image2_c:\n",
    "       x,y = points\n",
    "       points_H = np.array([x,y,1])\n",
    "       x_n,y_n,z_n = H_2@points_H\n",
    "       x_n,y_n = x_n/z_n, y_n/z_n\n",
    "       points_new.append((x_n,y_n))\n",
    "\n",
    "    for points in image1_c:\n",
    "       x,y = points\n",
    "       points_H = np.array([x,y,1])\n",
    "       x_n,y_n,z_n = H_2@H_4@points_H\n",
    "       x_n,y_n = x_n/z_n, y_n/z_n\n",
    "       points_new.append((x_n,y_n))\n",
    "       \n",
    "    for points in image5_c:\n",
    "       x,y = points\n",
    "       points_H = np.array([x,y,1])\n",
    "       x_n,y_n,z_n = H_1@H_3@points_H\n",
    "       x_n,y_n = x_n/z_n, y_n/z_n\n",
    "       points_new.append((x_n,y_n))\n",
    "    print(points_new)\n",
    "    \n",
    "    all_x = []\n",
    "    all_y = []\n",
    "\n",
    "    for (xc_d,yc_d) in image3_c:\n",
    "      all_x.append(xc_d)\n",
    "      all_y.append(yc_d)\n",
    "      \n",
    "    for (xc_s,yc_s) in points_new:\n",
    "       all_x.append(xc_s)\n",
    "       all_y.append(yc_s)\n",
    "\n",
    "    min_xc = min(all_x)\n",
    "    print(min_xc)\n",
    "    max_xc = max(all_x)\n",
    "    print(max_xc)\n",
    "    min_yc = min(all_y)\n",
    "    print(min_yc)\n",
    "    max_yc = max(all_y)\n",
    "    print(max_yc)\n",
    "\n",
    "    canvas_width = int(np.ceil(max_xc-min_xc))\n",
    "    canvas_height = int(np.ceil(max_yc-min_yc))\n",
    "\n",
    "    translate_x = max(0, -min_xc)\n",
    "    translate_y = max(0, -min_yc)  \n",
    "\n",
    "    return canvas_width,canvas_height,translate_x,translate_y \n",
    "\n",
    "\n",
    "#Using the Linear Blending all the 4 transformed images wrt image 3 are placed in the empty canvas with image linear blending and plotting the results \n",
    "\n",
    "canvas_width,canvas_height,translate_x,translate_y = canvas_creator(pts_im3corners,pts_im2corners,pts_im4corners,pts_im1corners,pts_im5corners)\n",
    "\n",
    "T = np.array([[1,0,translate_x],[0,1,translate_y],[0,0,1]], dtype=np.float64)\n",
    "\n",
    "canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
    "\n",
    "canv_im3 = cv2.warpPerspective(image3,T,(canvas_width,canvas_height))\n",
    "canv_im4 = cv2.warpPerspective(image4,T@H_1,(canvas_width,canvas_height))\n",
    "canv_im2 = cv2.warpPerspective(image2,T@H_2,(canvas_width,canvas_height))\n",
    "canv_im1 = cv2.warpPerspective(image1,T@H_2@H_4,(canvas_width,canvas_height))\n",
    "canv_im5 = cv2.warpPerspective(image5,T@H_1@H_3,(canvas_width,canvas_height))\n",
    "\n",
    "alpha = 0.3\n",
    "beta = 1.0 - alpha\n",
    "\n",
    "result = canv_im3.copy()\n",
    "result = cv2.addWeighted(result, alpha, canv_im4, beta, 0)\n",
    "result = cv2.addWeighted(result, alpha, canv_im2, beta, 0)\n",
    "result = cv2.addWeighted(result, alpha, canv_im1, beta, 0) \n",
    "\n",
    "final_panorama = cv2.addWeighted(result, alpha, canv_im5, beta, 0)\n",
    "\n",
    "\n",
    "plt.imshow(final_panorama)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc225c19",
   "metadata": {},
   "source": [
    "Difference in 2 different blending methods\n",
    "\n",
    "-in the openCV tutorial the blending of the images were not dependent on the frequencies of the pixel this method treated all pixel equally and applied the linear blending uniformly which ended up showing some ghosting artifacts, blurring of fine details and quite a few visible seams \n",
    "\n",
    "-the Burt & Adelson Pyramid approach where the images are decomposed into multiple frequency bands, first using gausian pyramid we sample by using low pass filter which creates the pyramid with lowest frequecy image on the top of the pyramid then by using Laplacian Pyramid the High Frequencies are defined for both images and the laplacian Pyramids are blended using gausian pyramid as weights to blend both image at each level and then collapse all levels into single\n",
    "\n",
    "#i have used ChatGpt to help understand the concept of the pyramid approach blending "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c052d8d3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
